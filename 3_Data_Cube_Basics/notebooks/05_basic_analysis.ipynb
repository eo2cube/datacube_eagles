{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"../../additional_data/banner_siegel.png\" style=\"width:1000px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Spatial Analysis\n",
    "\n",
    "* [**Sign up to the JupyterHub**](https://www.phenocube.org/) to run this notebook interactively from your browser\n",
    "* **Compatibility:** Notebook currently compatible with the Open Data Cube environments of the University of Wuerzburg\n",
    "* **Prerequisites**: It is recommended to work through the previous notebooks in this traning series and the \"spatial vector data\" notebook in the add-on series.\n",
    "    * How to run a [Jupyter notebook](01_jupyter_introduction.ipynb)\n",
    "    * The basic structure of the eo2cube [satellite datasets](02_eo2cube_introduction.ipynb)\n",
    "    * How to [lookup and load data](03_data_lookup_and_loading.ipynb)\n",
    "    * The basic structure of [xarray Dataset](04_xarrayI_data_structure.ipynb)\n",
    "    * Application of built-in [xarray functions](05_xarrayII.ipynb)\n",
    "    * How to use xarray to generate [basic plots](06_plotting_basics.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "In this notebook, we would present our readers a sample workflow of spatial data processing using spatial vector data and datasets in DataCube. Our aim in this notebook is to get a time series of some remote sensing indices and plot them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rioxarray as rio\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import odc.algo\n",
    "\n",
    "# Set config for displaying tables nicely\n",
    "# !! USEFUL !! otherwise parts of longer infos won't be displayed in tables\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "# Connect to DataCube\n",
    "# argument \"app\" --- user defined name for a session (e.g. choose one matching the purpose of this notebook)\n",
    "dc = datacube.Datacube()\n",
    "from odc.ui import with_ui_cbk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets\n",
    "\n",
    "Now, we load the data with `dc.load()` using the calculated x and y ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.list_products()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "product = \"s2_l2a\"\n",
    "measurements = dc.list_measurements()\n",
    "measurements.loc[product]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Area of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we have will load our region of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_fields = gpd.read_file('../sample_data/sample_fields.shp')\n",
    "sample_fields = sample_fields.to_crs(\"EPSG:4326\")\n",
    "sample_fields.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we extract the bounding box of our shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sample_fields.total_bounds[[0,2]] # extract longitude extents\n",
    "y = sample_fields.total_bounds[[1,3]] # extract latitude extents\n",
    "\n",
    "print('longitude_extents ' + str(x))\n",
    "print('latitude_extents ' + str(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to load our Sentinel-2 datasets for our RoI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "ds = dc.load(product= \"s2_l2a\",\n",
    "                  x= x,\n",
    "                  y= y,\n",
    "                  time = (\"2020-01-01\", \"2020-05-31\"), # specifiy time_extent\n",
    "                  output_crs = \"EPSG:32632\",\n",
    "                  measurements = [\"blue\", \"green\", \"red\", \"nir_1\"],\n",
    "                  resolution = (-10,10),\n",
    "                  group_by = \"solar_day\", \n",
    "                  #data_coverage = 100,\n",
    "                  progress_cbk=with_ui_cbk())# shows progress with loading bar\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the different images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dea_tools.plotting import rgb\n",
    "\n",
    "rgb(ds , index = [3,8,9,10,12,20,25,30], bands = [\"nir_1\", \"green\", \"blue\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate selected Remote Sensing Indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now calculate the NDVI. When we look at our dataset again we can see that the red and the green band are stored in uint16. In order to calculate the NDVI properly we first have to convert these into float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds =  odc.algo.to_f32(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply the function and write back the results to the xarray dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['ndvi'] = (ds.nir_1 - ds.red)/(ds.nir_1 + ds.red)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.ndvi.isel(time=3).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end we can just aggregate the NDVI for each time step and create a time series plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.ndvi.mean(['x', 'y']).plot.line('b-^', figsize=(11,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading cloud free images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above we have seen that we have a lot of clouds in our Sentinel-2 scenes. In most cases we want to avoid cloud pixels in our analysis. In order to exclude clouds from our data beforehand we can use the load_ard function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deafrica_tools.datahandling import load_ard\n",
    "ds = load_ard(dc=dc,\n",
    "            products=['s2_l2a'],\n",
    "            x= x,\n",
    "            y= y,\n",
    "            time = (\"2020-01-01\", \"2020-12-31\"), # specifiy time_extent\n",
    "            output_crs = \"EPSG:32632\",\n",
    "            measurements = ['red', 'green', 'blue', 'nir_1'],\n",
    "            resolution = (-10,10),\n",
    "            group_by = \"solar_day\",\n",
    "            mask_pixel_quality=True,\n",
    "            data_coverage = 100,\n",
    "            min_gooddata=0.90,    \n",
    "             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb(ds , index = [3,8,9], bands = [\"nir_1\", \"green\", \"blue\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we will use the calculate_indices function. This function allows us to calculate multiple predefined band indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deafrica_tools.bandindices import calculate_indices\n",
    "\n",
    "ds = calculate_indices(ds, index=['NDVI','EVI','SAVI'], collection='s2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can have a look at our cloud free NDVI time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.NDVI.isel(time = [1,2,3,4,5,6]).plot(col='time', cmap='RdYlGn') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.NDVI.median(['x', 'y']).plot.line('b-^', figsize=(11,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.DataFrame({\"time\": ds.time.values})\n",
    "data_frame = data_frame.set_index('time')\n",
    "data_frame['NDVI'] = ds.NDVI.median(['x', 'y']).values\n",
    "data_frame['EVI'] = ds.EVI.median(['x', 'y']).values\n",
    "data_frame['SAVI'] = ds.SAVI.median(['x', 'y']).values\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define figure style\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_context(\"poster\", font_scale = .7)\n",
    "\n",
    "# plot\n",
    "ax = data_frame.plot(figsize=[15,7], linewidth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommended next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue working through the notebooks in this beginner's guide, the following notebooks are designed to be worked through in the following order:\n",
    "\n",
    "1. [Jupyter Notebooks](https://github.com/eo2cube/eo2cube_notebooks/blob/main/get_started/intro_to_eo2cube/01_jupyter_introduction.ipynb)\n",
    "2. [eo2cube](https://github.com/eo2cube/eo2cube_notebooks/blob/main/get_started/intro_to_eo2cube/02_eo2cube_introduction.ipynb)\n",
    "3. [Loading Data](https://github.com/eo2cube/eo2cube_notebooks/blob/main/get_started/intro_to_eo2cube/03_data_lookup_and_loading.ipynb)\n",
    "4. [Xarray I: Data Structure](https://github.com/eo2cube/eo2cube_notebooks/blob/main/get_started/intro_to_eo2cube/04_xarrayI_data_structure.ipynb)\n",
    "5. [Xarray II: Index and Statistics](https://github.com/eo2cube/eo2cube_notebooks/blob/main/get_started/intro_to_eo2cube/05_xarrayII.ipynb)\n",
    "6. [Plotting data](https://github.com/eo2cube/eo2cube_notebooks/blob/main/get_started/intro_to_eo2cube/06_plotting_basics.ipynb)\n",
    "7. ***Spatial analysis (this notebook)***\n",
    "8. [Parallel processing with Dask](https://github.com/eo2cube/eo2cube_notebooks/blob/main/get_started/intro_to_eo2cube/08_parallel_processing_with_dask.ipynb)\n",
    "\n",
    "The additional notebooks are designed for users to build up both basic and advanced skills which are not covered by the beginner's guide. Self-motivated users can go through them according to their own needs. They act as complements for the guide:\n",
    "<br>\n",
    "\n",
    "1. [Python's file management tools](https://github.com/eo2cube/eo2cube_notebooks/blob/main/get_started/intro_to_eo2cube/I_file_management.ipynb)\n",
    "2. [Image Processing basics using NumPy and Matplotlib](https://github.com/eo2cube/eo2cube_notebooks/blob/main/get_started/intro_to_eo2cube/II_numpy_image_processing.ipynb)\n",
    "3. [Vector Processing](https://github.com/eo2cube/eo2cube_notebooks/blob/main/get_started/intro_to_eo2cube/III_process_vector_data.ipynb)\n",
    "4. [Advanced Plotting](https://github.com/eo2cube/eo2cube_notebooks/blob/main/get_started/intro_to_eo2cube/IV_advanced_plotting.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "<font size=\"2\">This notebook for the usage in the Open Data Cube entities of the [Department of Remote Sensing](http://remote-sensing.org/), [University of Wuerzburg](https://www.uni-wuerzburg.de/startseite/), is adapted from [Geoscience Australia](https://github.com/GeoscienceAustralia/dea-notebooks), published using the Apache License, Version 2.0. Thanks! </font>\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Australia data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "\n",
    "**Contact:** If you would like to report an issue with this notebook, you can file one on [Github](https://github.com).\n",
    "\n",
    "**Last modified:** May 2021"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
