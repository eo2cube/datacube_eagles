{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Practical Machine Learning\n",
    "## Supervised vs. Unsupervised Learning\n",
    "\n",
    "modified after [Sven Mayer](https://sven-mayer.com) \n",
    "### References\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\n",
    "* https://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane_unbalanced.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-learn, see https://scikit-learn.org\n",
    "import sklearn\n",
    "import sklearn.svm\n",
    "import sklearn.datasets\n",
    "\n",
    "# Math operations\n",
    "import numpy as np\n",
    "\n",
    "# Drawing functions\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating two clusters with random points on a 2D plain grouped in two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = [500, 500]\n",
    "centers = [[0.0, 0.0], [3.0, 3.0]]\n",
    "clusters_std = [1.5, 0.5]\n",
    "x, y = sklearn.datasets.make_blobs(n_samples=number_of_samples, centers=centers,\n",
    "                                   cluster_std=clusters_std, shuffle=True,\n",
    "                                   random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 50\n",
    "\n",
    "plt.scatter(x[y==1][:i, 0], x[y==1][:i, 1], c=\"#00ff80\", label=\"Tree\")\n",
    "plt.scatter(x[y==0][:i, 0], x[y==0][:i, 1], c=\"blue\", label=\"Water\")\n",
    "plt.xlim(-5,5)\n",
    "plt.ylim(-5,5)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#plt.savefig(\"treewater-cluster-050.png\", dpi=500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 500\n",
    "\n",
    "plt.scatter(x[y==1][:i, 0], x[y==1][:i, 1], c=\"#00ff80\", label=\"Tree\")\n",
    "plt.scatter(x[y==0][:i, 0], x[y==0][:i, 1], c=\"blue\", label=\"Water\")\n",
    "plt.xlim(-5,5)\n",
    "plt.ylim(-5,5)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#plt.savefig(\"treewater-cluster-500.png\", dpi=500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the first linear SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the first i samples\n",
    "i = 50\n",
    "\n",
    "#specify the SVMs parameter\n",
    "classifier = sklearn.svm.SVC(C=10, gamma=\"scale\", kernel=\"linear\")#, kernel=\"linear\")\n",
    "\n",
    "\n",
    "# train the SVM\n",
    "classifier.fit(x[:i], y[:i])\n",
    "\n",
    "## plot the results\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "plt.scatter(x[y==1][:i, 0], x[y==1][:i, 1], alpha=0.5, c=\"#00ff80\", label=\"Tree\")\n",
    "plt.scatter(x[y==0][:i, 0], x[y==0][:i, 1], alpha=0.5, c=\"blue\", label=\"Water\")\n",
    "\n",
    "\n",
    "# calculate and plot decision boundary\n",
    "xx = np.linspace(-5, 5, 30)\n",
    "yy = np.linspace(-5, 5, 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = classifier.decision_function(xy).reshape(XX.shape)\n",
    "ax.contour(XX, YY, Z, colors='gray', levels=[-1, 0, 1],  linestyles=['--', '-', '--'])\n",
    "\n",
    "plt.xlim(-5,5)\n",
    "plt.ylim(-5,5)\n",
    "plt.legend()\n",
    "plt.savefig(\"treewater-svm-050-linear.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot the results\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "i = 500\n",
    "\n",
    "plt.scatter(x[y==1][:i, 0], x[y==1][:i, 1], alpha=0.5, c=\"#00ff80\", label=\"Tree\")\n",
    "plt.scatter(x[y==0][:i, 0], x[y==0][:i, 1], alpha=0.5, c=\"blue\", label=\"Water\")\n",
    "#plt.scatter(X[:i, 0], X[:i, 1], c=y[:i], alpha=0.5, cmap=\"winter\", label=\"Data points\")\n",
    "\n",
    "\n",
    "# calculate and plot decision boundary\n",
    "xx = np.linspace(-5, 5, 30)\n",
    "yy = np.linspace(-5, 5, 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = classifier.decision_function(xy).reshape(XX.shape)\n",
    "ax.contour(XX, YY, Z, colors='grey', levels=[-1, 0, 1],  linestyles=['--', '-', '--'])\n",
    "plt.xlim(-5,5)\n",
    "plt.ylim(-5,5)\n",
    "plt.legend()\n",
    "#plt.savefig(\"treewater-svm-500-linear.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.scatter(x[:, 0], x[:, 1], c=\"gray\", alpha=0.5, label=\"Unknown Class\")\n",
    "plt.xlim(-5,5)\n",
    "plt.ylim(-5,5)\n",
    "plt.legend()\n",
    "plt.savefig(\"treewater-kmeans-unknown.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sklearn.cluster.KMeans(n_clusters=2).fit_predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "plt.scatter(x[y_pred == 1][:, 0], x[y_pred == 1][:, 1], alpha=0.5, c=\"red\", label=\"?\")\n",
    "plt.scatter(x[y_pred == 0][:, 0], x[y_pred == 0][:, 1], alpha=0.5, c=\"orange\", label=\"?\")\n",
    "plt.xlim(-5,5)\n",
    "plt.ylim(-5,5)\n",
    "plt.legend()\n",
    "plt.savefig(\"treewater-kmeans-cluster.png\", dpi=500, bbox_inches = 'tight', pad_inches = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code source: Gaël Varoquaux\n",
    "#              Andreas Müller\n",
    "# Modified for sklearn ocumentation by Jaques Grobler, adapted by Sebastian Förtsch\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "h = 0.2  # step size in the mesh\n",
    "\n",
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Linear SVM\",\n",
    "    \"RBF SVM\",\n",
    "    \"Gaussian Process\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"Neural Net\",\n",
    "    \"AdaBoost\",\n",
    "    \"Naive Bayes\",\n",
    "    \"QDA\",\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "]\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_features=2, n_redundant=0, n_informative=2, random_state=1, n_clusters_per_class=1\n",
    ")\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "datasets = [\n",
    "    make_moons(noise=0.3, random_state=0),\n",
    "    make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "    linearly_separable,\n",
    "]\n",
    "\n",
    "figure = plt.figure(figsize=(20, 9))\n",
    "i = 1\n",
    "# iterate over datasets\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.4, random_state=42\n",
    "    )\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "    # just plot the dataset first\n",
    "    cm = plt.cm.gnuplot\n",
    "    cm_bright = ListedColormap([\"#ff00a6\", \"#15ff00\"])\n",
    "    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "    if ds_cnt == 0:\n",
    "        ax.set_title(\"Input data\")\n",
    "    # Plot the training points\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\")\n",
    "    # Plot the testing points\n",
    "    ax.scatter(\n",
    "        X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6, edgecolors=\"k\"\n",
    "    )\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    i += 1\n",
    "\n",
    "    # iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "\n",
    "        # Plot the decision boundary. For that, we will assign a color to each\n",
    "        # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "        if hasattr(clf, \"decision_function\"):\n",
    "            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        else:\n",
    "            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "        # Put the result into a color plot\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        ax.contourf(xx, yy, Z, cmap=cm, alpha=.6)\n",
    "\n",
    "        # Plot the training points\n",
    "        ax.scatter(\n",
    "            X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\"\n",
    "        )\n",
    "        # Plot the testing points\n",
    "        ax.scatter(\n",
    "            X_test[:, 0],\n",
    "            X_test[:, 1],\n",
    "            c=y_test,\n",
    "            cmap=cm_bright,\n",
    "            edgecolors=\"k\",\n",
    "            alpha=0.6,\n",
    "        )\n",
    "\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        if ds_cnt == 0:\n",
    "            ax.set_title(name)\n",
    "        ax.text(\n",
    "            xx.max() - 0.3,\n",
    "            yy.min() + 0.3,\n",
    "            (\"%.2f\" % score).lstrip(\"0\"),\n",
    "            size=15,\n",
    "            horizontalalignment=\"right\",\n",
    "        )\n",
    "        i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"all\", dpi=500, bbox_inches = 'tight', pad_inches = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visit Sven Meyers course on [machine learning](https://sven-mayer.com/pml). Material are published using [Attribution-Share Alike 4.0 (CC BY-SA) license](https://creativecommons.org/licenses/by-sa/4.0), changes were not approved by the author and done by Sebastian Foertsch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
